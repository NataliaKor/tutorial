{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NataliaKor/tutorial/blob/main/tutorial-ML-for-GWPE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cf826081-c9ef-4aff-ba53-8e9b573ca2d8",
      "metadata": {
        "id": "cf826081-c9ef-4aff-ba53-8e9b573ca2d8"
      },
      "source": [
        "# Tutorial on Machine Learning for Gravitational Wave Parameter Estimation\n",
        "\n",
        "### Stephen Green *stephen.green2@nottingham.ac.uk* and Natalia Korsakova *korsakova@apc.in2p3.fr*\n",
        "\n",
        "---\n",
        "\n",
        "In this tutorial we build a simple parameter estimation neural network for galactic binaries.\n",
        "\n",
        "### Steps\n",
        "\n",
        "1. **Build a set of training waveforms.** We use the FastGB waveforms package.\n",
        "2. **Build a posterior model $q(\\theta | d)$** using a neural network. We consider two cases:\n",
        "    - Gaussian distribution with diagonal (learnable) covariance.\n",
        "    - Normalizing flow (RealNVP).\n",
        "3. **Train the model to represent the posterior**, i.e., $q(\\theta|d) \\to p(\\theta|d)$.\n",
        "    - During training, we add noise to waveforms to make simulated data.\n",
        "4. **Evaluate** on test data."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "213733c5-f5c3-484b-a9b0-f15f4a8fb0c3",
      "metadata": {
        "id": "213733c5-f5c3-484b-a9b0-f15f4a8fb0c3"
      },
      "source": [
        "## Imports\n",
        "\n",
        "We use the [PyTorch](https://pytorch.org) ML library. Waveforms are generated using a modified version of FastGB, available from Natalia's github."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting corner\n",
            "  Downloading corner-2.2.1-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: matplotlib>=2.1 in /usr/local/lib/python3.7/dist-packages (from corner) (3.2.2)\n",
            "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.1->corner) (1.21.6)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.1->corner) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.1->corner) (1.4.4)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.1->corner) (3.0.9)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.1->corner) (2.8.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib>=2.1->corner) (4.1.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib>=2.1->corner) (1.15.0)\n",
            "Installing collected packages: corner\n",
            "Successfully installed corner-2.2.1\n"
          ]
        }
      ],
      "source": [
        "# Plotting library not included in colab.\n",
        "!pip install corner"
      ],
      "metadata": {
        "id": "IhOwfXGdExWT",
        "outputId": "660ae77d-b3ff-475d-9cf7-2a3bb218c9da",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "IhOwfXGdExWT"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "A2xwybJfHGvQ",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A2xwybJfHGvQ",
        "outputId": "3e0d855a-64f3-4fc8-f1c2-da44c7c92b89"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'GBGPU'...\n",
            "remote: Enumerating objects: 1141, done.\u001b[K\n",
            "remote: Counting objects: 100% (315/315), done.\u001b[K\n",
            "remote: Compressing objects: 100% (213/213), done.\u001b[K\n",
            "remote: Total 1141 (delta 145), reused 222 (delta 100), pack-reused 826\u001b[K\n",
            "Receiving objects: 100% (1141/1141), 12.08 MiB | 25.51 MiB/s, done.\n",
            "Resolving deltas: 100% (635/635), done.\n"
          ]
        }
      ],
      "source": [
        "# Waveform generation libary based on FastGB plus noise curve for LISA.\n",
        "!git clone https://github.com/NataliaKor/GBGPU.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "id": "ZF-3zFO1FBrr",
      "metadata": {
        "id": "ZF-3zFO1FBrr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "16a54ac1-fffc-4c5d-dd53-5b5a07d326ce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "from torch import nn\n",
        "from torch import distributions\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import corner\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "# Making code agnostic to CPU/GPU\n",
        "def std_get_wrapper(arg):\n",
        "    return arg\n",
        "\n",
        "def cuda_get_wrapper(arg):\n",
        "    return arg.get()\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "   import cupy as cp\n",
        "   gpu = True\n",
        "   get_wrapper = cuda_get_wrapper\n",
        "else:\n",
        "   import numpy as cp\n",
        "   gpu = False\n",
        "   get_wrapper = std_get_wrapper\n",
        "\n",
        "print(gpu)\n",
        "\n",
        "from GBGPU.gbgpu.gbgpu import GBGPU\n",
        "from GBGPU.gbgpu.noisemodel import AnalyticNoise "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "079534ec-42e2-4e47-b9cb-d6189bc2eb9e",
      "metadata": {
        "id": "079534ec-42e2-4e47-b9cb-d6189bc2eb9e"
      },
      "source": [
        "## Training data\n",
        "\n",
        "### Signal model\n",
        "\n",
        "The galactic binary waveforms that we use depend on 8 parameters $\\theta$:\n",
        "* Amplitude `amp`\n",
        "* Initial frequency `f0` (Hz)\n",
        "* Initial time derivative of frequency `fdot` (Hz/s)\n",
        "* Initial phase angle of gravitational wave `phi0` (radians)\n",
        "* Inclination of the orbit `iota` (radians)\n",
        "* Ecliptic longitude `lam` (radians)\n",
        "* Ecliptic lattitude `beta` (radians)\n",
        "* Polarization angle `psi` (radians)\n",
        "\n",
        "The FastGB package then gives us waveforms $h(\\theta) = (A(\\theta), E(\\theta))$ where $A$, $E$ are TDI channels.\n",
        "\n",
        "Initially, we perform inference over `amp` and `f0`, holding the remaining parameters at fixed values. Training data must be drawn from the prior, and we choose uniform `amp`, `f0` priors over some range.\n",
        "\n",
        "### Noise\n",
        "\n",
        "Ultimately we must train on simulated data, which also include noise,\n",
        "$$\n",
        "d = h(\\theta) + n, \\qquad n \\sim p_{S_n}(n).\n",
        "$$\n",
        "The noise is taken to be stationary Gaussian with some power spectral density $S_n$.\n",
        "\n",
        "Rather than creating complete simulated data sets in advance of training, **we only prepare the waveforms in advance, and we add noise realizations during training.** The reason for this is that we would like the training dataset to be as large as possible to reduce the risk of overfitting. Noise is fast to sample, so this can be done during training, and doing so effectively makes the training set much larger. Generally waveforms are slower to generate, so general practice is to re-use them in each epoch. However with a very fast waveform model (e.g., using GPU acceleration) training could be further improved by generating all data on the fly."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9493c3ba-3b93-4cf4-847d-e7360029e2a3",
      "metadata": {
        "id": "9493c3ba-3b93-4cf4-847d-e7360029e2a3"
      },
      "source": [
        "### Parameter sampling\n",
        "\n",
        "Initially, we construct a dataset consisting of $10^4$ waveforms, all drawn from the prior."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "49802b93-371b-4463-9469-7d3ce76d9816",
      "metadata": {
        "id": "49802b93-371b-4463-9469-7d3ce76d9816"
      },
      "outputs": [],
      "source": [
        "# Size of the training set.\n",
        "num_samples = 10000\n",
        "\n",
        "# We choose a very narrow frequency range.\n",
        "f0_lower = 0.010062\n",
        "f0_upper = 0.010084\n",
        "\n",
        "# Amplitude range.\n",
        "amp_lower = 1e-23\n",
        "amp_upper = 1e-21\n",
        "\n",
        "# Sample f0 and amp from a uniform prior.\n",
        "f0 = cp.random.uniform(f0_lower, f0_upper, num_samples)\n",
        "amp = cp.random.uniform(amp_lower, amp_upper, num_samples)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "658f2fda-270f-4895-8dc6-23079de2b42a",
      "metadata": {
        "id": "658f2fda-270f-4895-8dc6-23079de2b42a"
      },
      "outputs": [],
      "source": [
        "# Fixed parameters\n",
        "ones = cp.ones(num_samples)\n",
        "fdot = 1.79e-15 * ones\n",
        "lam  = 4.36 * ones\n",
        "beta = 2.18 * ones\n",
        "iota = 0.67 * ones\n",
        "phi0 = 5.48 * ones\n",
        "psi  = 0.43 * ones"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "outputs": [],
      "source": [
        "# Package parameters into arrays.\n",
        "\n",
        "sampling_parameters = cp.vstack((f0, amp)).T\n",
        "all_parameters = cp.vstack((amp, f0, fdot, cp.zeros(num_samples), -phi0, iota, psi, lam, beta)).T"
      ],
      "metadata": {
        "id": "Woo8539YExWc"
      },
      "id": "Woo8539YExWc"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Waveform generation"
      ],
      "metadata": {
        "collapsed": false,
        "id": "lWNTqdvZExWd"
      },
      "id": "lWNTqdvZExWd"
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "outputs": [],
      "source": [
        "# Initialise waveform generator.\n",
        "gb = GBGPU(use_gpu=gpu)\n",
        "\n",
        "# Waveform settings\n",
        "Tobs = 31536000.0  # One-year observation\n",
        "dt = 15.0  # Sample rate (Nyquist is safely larger than the maximum frequency we will encounter)\n",
        "df = 1./Tobs\n",
        "N_points = 128\n",
        "\n",
        "# Generate the waveforms.\n",
        "gb.run_wave(*all_parameters.T, N = N_points, dt = dt, T = Tobs, oversample = 1)"
      ],
      "metadata": {
        "id": "y_fZiksXExWd"
      },
      "id": "y_fZiksXExWd"
    },
    {
      "cell_type": "markdown",
      "source": [
        "The waveforms stored in `gb` are only defined over very narrow frequency support. They need to be stitched into a wider frequency band, which we define here. We choose a frequency range slightly larger than [f0_lower, f0_upper] such that full waveform can always fit in a band."
      ],
      "metadata": {
        "collapsed": false,
        "id": "pA4sAtFMExWe"
      },
      "id": "pA4sAtFMExWe"
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "eb451fda-85f5-42d4-93db-0fc0d5fe3dc5",
      "metadata": {
        "id": "eb451fda-85f5-42d4-93db-0fc0d5fe3dc5"
      },
      "outputs": [],
      "source": [
        "f_min = 0.010059\n",
        "f_max = 0.0100861\n",
        "\n",
        "# Define the frequency grid.\n",
        "num_bins = int((f_max - f_min) / df) + 1\n",
        "sample_frequencies = cp.linspace(f_min, f_max, num=num_bins)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "69d16b7c-4eee-4753-874c-241fbbe16b0a",
      "metadata": {
        "id": "69d16b7c-4eee-4753-874c-241fbbe16b0a"
      },
      "source": [
        "Neural networks perform best when inputs are standardized. For simulated data, we achieve this by whitening the waveforms using the predicted LISA power spectral density."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "id": "5a6c9114-8c49-4e58-b91d-04ddedd3047a",
      "metadata": {
        "id": "5a6c9114-8c49-4e58-b91d-04ddedd3047a"
      },
      "outputs": [],
      "source": [
        "noise = AnalyticNoise(sample_frequencies)\n",
        "psd_A, psd_E = noise.psd(option=\"A\"), noise.psd(option=\"E\")\n",
        "\n",
        "asd_A = cp.sqrt(psd_A)\n",
        "asd_E = cp.sqrt(psd_E)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "391c3ddd-6eff-40d3-8d27-59994823b250",
      "metadata": {
        "id": "391c3ddd-6eff-40d3-8d27-59994823b250"
      },
      "outputs": [],
      "source": [
        "plt.plot(get_wrapper(sample_frequencies), get_wrapper(asd_A))\n",
        "plt.title('Amplitude spectral density in a band')\n",
        "plt.xlabel('frequency (Hz)')\n",
        "plt.ylabel('amplitude spectral density (channel A)')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally, we stitch the waveforms into the frequency grid, and at the same time apply the whitening."
      ],
      "metadata": {
        "collapsed": false,
        "id": "0Vmpffi8ExWg"
      },
      "id": "0Vmpffi8ExWg"
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "id": "U12avMJo6NSX",
      "metadata": {
        "id": "U12avMJo6NSX"
      },
      "outputs": [],
      "source": [
        "k_min = round(f_min/df)\n",
        "k_max = round(f_max/df)\n",
        "num = len(sample_frequencies)\n",
        "\n",
        "# These indices describe how to stitch the waveform into the larger frequency grid.\n",
        "i_start = (get_wrapper(gb.start_inds) - k_min).astype(cp.int32)\n",
        "i_end = (get_wrapper(gb.start_inds) - k_min + gb.N).astype(cp.int32)\n",
        "\n",
        "# PyTorch by default uses float32, and that should be sufficient for our purposes.\n",
        "# Here we use complex64 since the frequency-domain strain is complex.\n",
        "\n",
        "A_whitened = cp.empty((num_samples, num), dtype=cp.complex64)\n",
        "E_whitened = cp.empty((num_samples, num), dtype=cp.complex64)\n",
        "\n",
        "for i in range(num_samples):\n",
        "    x = cp.zeros(num, dtype=cp.complex128)\n",
        "    x[i_start[i]:i_end[i]] = gb.A[i]\n",
        "    x *= cp.sqrt(4 * df) / asd_A\n",
        "    A_whitened[i] = x\n",
        "    \n",
        "    x = cp.zeros(num, dtype=cp.complex128)\n",
        "    x[i_start[i]:i_end[i]] = gb.E[i]\n",
        "    x *= cp.sqrt(4 * df) / asd_E\n",
        "    A_whitened[i] = x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "93b603a8-ce6e-4202-a2e5-c85175fb308c",
      "metadata": {
        "id": "93b603a8-ce6e-4202-a2e5-c85175fb308c"
      },
      "outputs": [],
      "source": [
        "# Plot a sample waveform\n",
        "plt.plot(get_wrapper(sample_frequencies), get_wrapper(A_whitened[0].real))\n",
        "plt.xscale('log')\n",
        "plt.xlabel('$f$')\n",
        "plt.ylabel('Re $A$')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2b6a557d-38c1-41a6-a038-419f0d13425d",
      "metadata": {
        "id": "2b6a557d-38c1-41a6-a038-419f0d13425d"
      },
      "source": [
        "### Package into a pytorch Dataset\n",
        "\n",
        "The `Dataset` is a convenient class for storing and accessing pairs of parameters and associated data. It must define the following methods:\n",
        "\n",
        "* `__len__()`: Return total number of samples in the dataset.\n",
        "* `__getitem__(idx)`: Retrieve a $(\\theta, d)$ pair of parameters and data. We use this method to also add (in real time) a noise realization to each simulated waveform. (Therefore repeated calls will give different noise realizations).\n",
        "\n",
        "For now, we will only make use of the $A$ channel for simplicity, although it is straightforward to extend to include $E$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "583a1d63-01d0-42db-bbf2-7db0adc598a9",
      "metadata": {
        "id": "583a1d63-01d0-42db-bbf2-7db0adc598a9"
      },
      "outputs": [],
      "source": [
        "# For best training, parameters should be standardized (zero mean, unit variance across the training set).\n",
        "\n",
        "parameters_mean = np.mean(sampling_parameters, axis=0)\n",
        "parameters_std = np.std(sampling_parameters, axis=0)\n",
        "\n",
        "parameters_standardized = (sampling_parameters - parameters_mean) / parameters_std\n",
        "parameters_standardized = parameters_standardized.astype(np.float32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "id": "b8ac66e6-40ad-404e-bbdf-af94e8c48bcc",
      "metadata": {
        "id": "b8ac66e6-40ad-404e-bbdf-af94e8c48bcc"
      },
      "outputs": [],
      "source": [
        "# Prepare the (complex) frequency-domain data for the (real) neural network. To do so we simply concatenate the real and imaginary parts into an array of doubled length.\n",
        "\n",
        "waveforms = cp.hstack((A_whitened.real, A_whitened.imag))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "id": "2d8bcd70-4575-4e3f-adeb-bc2b91789e35",
      "metadata": {
        "id": "2d8bcd70-4575-4e3f-adeb-bc2b91789e35"
      },
      "outputs": [],
      "source": [
        "class WaveformDataset(Dataset):\n",
        "    \n",
        "    def __init__(self, parameters, waveforms):\n",
        "        self.parameters = parameters\n",
        "        self.waveforms = waveforms\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.parameters)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        params = self.parameters[idx]\n",
        "        signal = self.waveforms[idx]\n",
        "        \n",
        "        # Add unit normal noise to the signal\n",
        "        noise = cp.random.normal(size = signal.shape).astype(cp.float32)\n",
        "        data = signal + noise\n",
        "        \n",
        "        return torch.tensor(data), torch.tensor(params)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "id": "9962f84b-f12b-42e8-ad63-d713fd026c66",
      "metadata": {
        "id": "9962f84b-f12b-42e8-ad63-d713fd026c66"
      },
      "outputs": [],
      "source": [
        "waveform_dataset = WaveformDataset(parameters_standardized, waveforms)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "94b3df66-380e-475e-805e-bd8c0adb32dc",
      "metadata": {
        "id": "94b3df66-380e-475e-805e-bd8c0adb32dc"
      },
      "outputs": [],
      "source": [
        "# We can sample from the WaveformDataset. This gives us pairs of data and parameters, different noise realizations each time.\n",
        "\n",
        "x, y = waveform_dataset[0]\n",
        "plt.plot(x)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cd5a15e1-7686-4f4d-a02c-23b6d035833a",
      "metadata": {
        "id": "cd5a15e1-7686-4f4d-a02c-23b6d035833a"
      },
      "source": [
        "## Gaussian posterior model\n",
        "\n",
        "We now try to fit the posterior using a Gaussian model, i.e.,\n",
        "\n",
        "$$\n",
        "q(\\theta|d) = \\mathcal{N}(\\mu(d), \\Sigma(d)) (\\theta).\n",
        "$$\n",
        "Here $\\mu$ and $\\Sigma$ are the mean and covariance matrix describing the Gaussian, and they are given as the output of a neural network, which takes as input the data $d$. Additionally, we constrain $\\Sigma$ to be diagonal, so we only learn the variance in each parameter, and we do not allow for correlations between parameters in the posterior. (**Exercise:** Lift this restriction.)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model construction\n",
        "\n",
        "Neural networks are constructed by subclassing `nn.Module`.\n",
        "\n",
        "This has to implement an `__init__()` and `forward()` method."
      ],
      "metadata": {
        "collapsed": false,
        "id": "_Q91cUVTExWk"
      },
      "id": "_Q91cUVTExWk"
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "id": "a30d2fb4-969c-4c83-ba1d-ffcb0024e6a1",
      "metadata": {
        "id": "a30d2fb4-969c-4c83-ba1d-ffcb0024e6a1"
      },
      "outputs": [],
      "source": [
        "class NeuralNetwork(nn.Module):\n",
        "    \n",
        "    def __init__(self, input_dim, hidden_dims, output_dim, activation=nn.ReLU()):\n",
        "        super(NeuralNetwork, self).__init__()\n",
        "        \n",
        "        # Hidden layers. Use a simple feedforward network.\n",
        "        hidden_net_list = []\n",
        "        hidden_net_list.append(\n",
        "            nn.Linear(input_dim, hidden_dims[0]))\n",
        "        for i in range(1, len(hidden_dims)):\n",
        "            hidden_net_list.append(nn.Linear(hidden_dims[i-1], hidden_dims[i]))\n",
        "        self.hidden_net_list = nn.ModuleList(hidden_net_list)\n",
        "        \n",
        "        # Output layers\n",
        "        self.output_mean = nn.Linear(hidden_dims[-1], output_dim)\n",
        "        self.output_log_sigma = nn.Linear(hidden_dims[-1], output_dim)\n",
        "        \n",
        "        # Activation function\n",
        "        self.activation = activation\n",
        "        \n",
        "    def forward(self, x):\n",
        "        \"\"\"Pass x through all the layers of the network and return the Gaussian distribution\"\"\"\n",
        "        \n",
        "        h = x\n",
        "        for layer in self.hidden_net_list:\n",
        "            h = self.activation(layer(h))\n",
        "\n",
        "        # Output layer defines a Gaussian\n",
        "        mean = self.output_mean(h)\n",
        "        log_sigma = self.output_log_sigma(h)\n",
        "        sigma = torch.exp(log_sigma)\n",
        "        \n",
        "        # Create the Gaussian distribution\n",
        "        dist = torch.distributions.MultivariateNormal(loc=mean, scale_tril=torch.diag_embed(sigma))\n",
        "        \n",
        "        return dist"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "id": "6d7cdfa4-1fe8-4993-a5f0-311889bba38d",
      "metadata": {
        "id": "6d7cdfa4-1fe8-4993-a5f0-311889bba38d"
      },
      "outputs": [],
      "source": [
        "input_dim = waveforms.shape[-1]\n",
        "output_dim = sampling_parameters.shape[-1]\n",
        "hidden_dims = [512, 256, 128, 64, 32]\n",
        "\n",
        "model = NeuralNetwork(input_dim, hidden_dims, output_dim)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b59d8148-32b1-4a46-952f-7625d1a32eac",
      "metadata": {
        "id": "b59d8148-32b1-4a46-952f-7625d1a32eac"
      },
      "outputs": [],
      "source": [
        "print(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7ee627d9-db98-4d9f-82f6-99e51264de02",
      "metadata": {
        "id": "7ee627d9-db98-4d9f-82f6-99e51264de02"
      },
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "id": "232f5f26-796f-484c-b52c-a035090ecb02",
      "metadata": {
        "id": "232f5f26-796f-484c-b52c-a035090ecb02"
      },
      "outputs": [],
      "source": [
        "# Split the dataset into training and test sets. We use the test set to make sure the network properly generalizes to data that it has not seen in training, i.e., it does not overfit.\n",
        "\n",
        "train_fraction = 0.8\n",
        "num_train = int(round(train_fraction * num_samples))\n",
        "num_test = num_samples - num_train\n",
        "train_dataset, test_dataset = random_split(waveform_dataset, [num_train, num_test])\n",
        "\n",
        "# The DataLoader is used in training.\n",
        "\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=256, shuffle=True)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=256, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "id": "16304af3-c970-416a-8520-1db669330f4c",
      "metadata": {
        "id": "16304af3-c970-416a-8520-1db669330f4c"
      },
      "outputs": [],
      "source": [
        "# The DataLoaders iterate over samples, returning torch tensors containing a batch of data.\n",
        "\n",
        "train_features, train_labels = next(iter(train_dataloader))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "id": "3ff8e2e9-f485-485d-8bc2-fc31d74afe18",
      "metadata": {
        "id": "3ff8e2e9-f485-485d-8bc2-fc31d74afe18"
      },
      "outputs": [],
      "source": [
        "# We use the Adam optimizer.\n",
        "\n",
        "optimizer = torch.optim.Adam([p for p in model.parameters() if p.requires_grad==True], lr=1e-3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "id": "594b543d-e129-4845-ace5-f6a387d6ad41",
      "metadata": {
        "id": "594b543d-e129-4845-ace5-f6a387d6ad41"
      },
      "outputs": [],
      "source": [
        "# Training and test loops.\n",
        "\n",
        "def train_loop(dataloader, model, optimizer):\n",
        " \n",
        "    size = len(dataloader.dataset)\n",
        "    train_loss = 0\n",
        "    \n",
        "    for batch, (X, y) in enumerate(dataloader):\n",
        "        # Compute negative log probability loss\n",
        "        dist = model(X)        \n",
        "        loss = - dist.log_prob(y)\n",
        "        \n",
        "        train_loss += loss.detach().sum()\n",
        "        loss = loss.mean()\n",
        "\n",
        "        # Backpropagation\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if batch % 50 == 0:\n",
        "            loss, current = loss.item(), batch * len(X)\n",
        "            print(f\"Loss: {loss:>7f}  [{current:>5d}/{size:>5d} samples]\")\n",
        "            \n",
        "    average_loss = train_loss.item() / size\n",
        "    print('Average loss: {:.4f}'.format(average_loss))\n",
        "    return average_loss\n",
        "            \n",
        "              \n",
        "def test_loop(dataloader, model):\n",
        "    size = len(dataloader.dataset)\n",
        "    test_loss = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for X, y in dataloader:\n",
        "            dist = model(X)\n",
        "            loss = - dist.log_prob(y)\n",
        "            test_loss += loss.sum()\n",
        "\n",
        "    test_loss /= size\n",
        "    print(f\"Test loss: {test_loss:>8f} \\n\")\n",
        "    return test_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "19a8d1ff-461a-4e1b-a11f-82946561b876",
      "metadata": {
        "id": "19a8d1ff-461a-4e1b-a11f-82946561b876"
      },
      "outputs": [],
      "source": [
        "epochs = 20\n",
        "train_history = []\n",
        "test_history = []\n",
        "for t in range(epochs):\n",
        "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
        "    loss = train_loop(train_dataloader, model, optimizer)\n",
        "    train_history.append(loss)\n",
        "    loss = test_loop(test_dataloader, model)\n",
        "    test_history.append(loss)\n",
        "print(\"Done!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "94965616-04d6-4466-be56-8e9f227f20d5",
      "metadata": {
        "id": "94965616-04d6-4466-be56-8e9f227f20d5"
      },
      "outputs": [],
      "source": [
        "epochs = np.arange(1, len(train_history) + 1)\n",
        "plt.plot(epochs, train_history, label = 'train loss')\n",
        "plt.plot(epochs, test_history, label = 'test loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Caution\n",
        "\n",
        "Looking at the loss curves, we see that we have clearly overfit the data! The train loss has been going down, but the test loss has started growing. A network trained like this would be unable to interpolate to new data, and would be useless for inference. The network is essentially memorizing the training data, which it can do because the training set is too small.\n",
        "\n",
        "#### Exercise\n",
        "\n",
        "Go back and fix this problem. Use $10^5$ training samples instead of $10^4$. Note that when you train the network, it will take 10 times longer because we are fixing the number of epochs, not the number of iterations. Having a larger dataset typically means that we can train longer without overfitting."
      ],
      "metadata": {
        "collapsed": false,
        "id": "do2CRoAHExWo"
      },
      "id": "do2CRoAHExWo"
    },
    {
      "cell_type": "markdown",
      "id": "c7639f37-f16d-4a64-b626-ed30d0111397",
      "metadata": {
        "id": "c7639f37-f16d-4a64-b626-ed30d0111397"
      },
      "source": [
        "### Evaluation\n",
        "\n",
        "Make some corner plots of the posterior distribution."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "num_posteriors = 3\n",
        "num_samples = 10000\n",
        "\n",
        "for n in range(num_posteriors):\n",
        "    test_x, test_y = test_dataset[n]\n",
        "\n",
        "    # Predict a posterior\n",
        "    dist = model(test_x)\n",
        "\n",
        "    # Sample the posterior\n",
        "    pred_samples = cp.asarray(dist.sample((10000,)))\n",
        "\n",
        "    # Undo the standardization\n",
        "    pred_samples = parameters_std * pred_samples + parameters_mean\n",
        "    truth = parameters_std * cp.asarray(test_y) + parameters_mean\n",
        "\n",
        "    # Plot\n",
        "    corner.corner(get_wrapper(pred_samples), truths=get_wrapper(truth), labels=['$f_0$', 'amplitude', '$\\iota$'])\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "rzKvk-fnExWp"
      },
      "id": "rzKvk-fnExWp"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Joint corner plot\n",
        "\n",
        "num_posteriors = 3\n",
        "num_samples = 10000\n",
        "\n",
        "cmap = plt.get_cmap('Set1')\n",
        "\n",
        "for n in range(num_posteriors):\n",
        "    test_x, test_y = test_dataset[n]\n",
        "\n",
        "    # Predict a posterior\n",
        "    dist = model(test_x)\n",
        "\n",
        "    # Sample the posterior\n",
        "    pred_samples = cp.asarray(dist.sample((10000,)))\n",
        "\n",
        "    # Undo the standardization\n",
        "    pred_samples = parameters_std * pred_samples + parameters_mean\n",
        "    truth = parameters_std * cp.asarray(test_y) + parameters_mean\n",
        "\n",
        "    # Plot\n",
        "    if n == 0:\n",
        "        fig = corner.corner(get_wrapper(pred_samples),\n",
        "                            truths=get_wrapper(truth),\n",
        "                            labels=['$f_0$', 'amp'],\n",
        "                            range=((f0_lower, f0_upper), (amp_lower, amp_upper)),\n",
        "                            color=cmap(n), truth_color=cmap(n))\n",
        "    else:\n",
        "        corner.corner(get_wrapper(pred_samples), truths=get_wrapper(truth), color=cmap(n), truth_color=cmap(n), fig=fig)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "F2RC-wHBExWp"
      },
      "id": "F2RC-wHBExWp"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Further exercises\n",
        "\n",
        "1. Train a network that samples also `iota`, so there are three parameters in total. Use the prior $p(\\iota) \\propto \\sin(\\iota)$, $0\\le\\iota\\le\\pi$. Hint: You can sample from the prior using `iota = np.arccos(1 - 2 * np.random.uniform(0, 1, num_samples))`.\n",
        "2. Notice that the posterior obtained do not capture the expected correlation between `amp` and `iota`. This is because the Gaussian network is forced to have diagonal covariance matrix. Try to learn the correlation by either (a) adding the off-diagonal elements to the Gaussian network, or (b) training a flow (below).\n",
        "3. Make a P--P plot.\n",
        "4. Infer also the sky position parameters `lam` and `beta`. For this, it is necessary to use data from both TDI channels $A$ and $E$. Extend the `WaveformDataset` class to include these.\n",
        "5. So far we have restricted ourselves to a single galactic binary in each data set, which is not a realistic expectation. Try to extend the model to infer the properties of two or more binaries at the same time."
      ],
      "metadata": {
        "collapsed": false,
        "id": "akCnF7aXExWp"
      },
      "id": "akCnF7aXExWp"
    },
    {
      "cell_type": "markdown",
      "id": "6c6k9N8VvSZ9",
      "metadata": {
        "id": "6c6k9N8VvSZ9"
      },
      "source": [
        "## Normalising flow\n",
        "\n",
        "The diagonal Gaussian distribution is not capable of capturing features present in complex posteriors, which could include correlations  between parameters and multimodality. For this reason we turn to more powerful density estimation networks, in particular normalising flows.\n",
        "\n",
        "A **normalising flow** is a mapping $f: u \\mapsto \\theta$ from a simple \"base distribution\" $\\pi(u)$ (typically standard normal) to a more complex one $q(\\theta)$. The mapping $f$ is itself parametrised using a neural network. Since the neural network is typically fast to evaluate, one can rapidly sample $\\theta \\sim q(\\theta)$ by first sampling $u\\sim \\pi(u)$ and setting $\\theta = f(u)$. One can also rapidly evaluate the density $q(\\theta)$ provided $f$ satisfies the following properties:\n",
        "1. $f$ is invertible,\n",
        "2. $f$ has simple Jacobian determinant.\n",
        "\n",
        "Indeed, by the change of variables rule, $q(\\theta) = \\pi(f^{-1}(\\theta)) | \\det J_{f^{-1}} |$, and one can easily evaluate the right hand side if (1) and (2) hold.\n",
        "\n",
        "A normalizing flow can also describe a **conditional distribution** $q(\\theta | d)$ if the flow is made to depend on $d$, in which case we denote it $f_d$. This is the case of interest for us, since we are modeling the Bayesian posterior.\n",
        "\n",
        "There are many different types of normalising flows, and here we will implement the [RealNVP](https://arxiv.org/abs/1605.08803)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "pm9fG1J71sgy",
      "metadata": {
        "id": "pm9fG1J71sgy"
      },
      "source": [
        "### RealNVP\n",
        "\n",
        "This is based on the simple affine transformation, where part of the dimensions are scaled and shifted.\n",
        "\n",
        "Let's assume that we separate the dimensions into two parts:\n",
        "$x_{1:d}$ and $x_{d+1:D}$  \n",
        "\n",
        "Half of the dimensions are kept unchanged:\n",
        "\n",
        "$y_{1:d} = x_{1:d}$\n",
        "\n",
        "Other half is transformed with affine transform. Lets define $t$ is a 'shift' function and $s$ is a 'scale' functions. We will parameterise them with neural networks. We apply this transformations to the first part of data:\n",
        "$s(x_{1:d})$ and $t(x_{1:d})$.\n",
        "\n",
        "Then we combine it with the data from the second half of dimensions and get:\n",
        "$y_{d+1:D} = x_{d+1:D} \\odot \\exp(s(x_{1:d})) + t(x_{1:d})$.\n",
        "\n",
        "-----------------------------------------------------------------------------\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "rzlqpuXoRWqI",
      "metadata": {
        "id": "rzlqpuXoRWqI"
      },
      "source": [
        "To divide dimensions we use a mask:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "annRvmYrRIg4",
      "metadata": {
        "id": "annRvmYrRIg4"
      },
      "outputs": [],
      "source": [
        "masks = torch.from_numpy(np.array([[0, 1], [1, 0]] * 3).astype(np.float32))\n",
        "masks"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "qxj4F7Y5ySca",
      "metadata": {
        "id": "qxj4F7Y5ySca"
      },
      "source": [
        "Transformations $s$ and $t$ :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "id": "yYn0Lsp_Q9Wt",
      "metadata": {
        "id": "yYn0Lsp_Q9Wt"
      },
      "outputs": [],
      "source": [
        "# Define functions s and t as simple fully connected networks:\n",
        "\n",
        "def t_func(input_dim, hidden_dims, output_dim):\n",
        "        \n",
        "    hidden_net_list = []\n",
        "    hidden_net_list.append(nn.Linear(input_dim, hidden_dims[0]))\n",
        "    for i in range(1, len(hidden_dims)):\n",
        "      hidden_net_list.append(nn.Linear(hidden_dims[i-1], hidden_dims[i]))\n",
        "      hidden_net_list.append(nn.ReLU())\n",
        "    hidden_net_list.append(nn.Linear(hidden_dims[i], output_dim))\n",
        "    \n",
        "    return nn.Sequential(*hidden_net_list)\n",
        " \n",
        "def s_func(input_dim, hidden_dims, output_dim):\n",
        "        \n",
        "    hidden_net_list = []\n",
        "    hidden_net_list.append(nn.Linear(input_dim, hidden_dims[0]))\n",
        "    for i in range(1, len(hidden_dims)):\n",
        "      hidden_net_list.append(nn.Linear(hidden_dims[i-1], hidden_dims[i]))\n",
        "      hidden_net_list.append(nn.ReLU())\n",
        "    hidden_net_list.append(nn.Linear(hidden_dims[i], output_dim))\n",
        "    hidden_net_list.append(nn.Tanh())\n",
        "\n",
        "    return nn.Sequential(*hidden_net_list) \n",
        "     \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "id": "5OZCJ-c48uR1",
      "metadata": {
        "id": "5OZCJ-c48uR1"
      },
      "outputs": [],
      "source": [
        "input_dim = waveforms.shape[-1] + sampling_parameters.shape[-1]\n",
        "output_dim = sampling_parameters.shape[-1]\n",
        "hidden_dims = [512, 256, 128, 64, 32]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "sVfi700pREHE",
      "metadata": {
        "id": "sVfi700pREHE"
      },
      "source": [
        "Base distribution is chosen to be Gaussian Multivariate Distribution.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "id": "GBjtAeIZxk4A",
      "metadata": {
        "id": "GBjtAeIZxk4A"
      },
      "outputs": [],
      "source": [
        "prior = distributions.MultivariateNormal(torch.zeros(2), torch.eye(2))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1xllEIiowFqJ",
      "metadata": {
        "id": "1xllEIiowFqJ"
      },
      "source": [
        "Implementation of the flow:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "id": "mFu9U9pA1-xS",
      "metadata": {
        "id": "mFu9U9pA1-xS"
      },
      "outputs": [],
      "source": [
        "class RealNVP_wf(nn.Module):\n",
        "    def __init__(self, s_func, t_func, mask, prior):\n",
        "        super(RealNVP_wf, self).__init__()\n",
        "        \n",
        "        self.prior = prior\n",
        "\n",
        "        self.register_buffer('mask', mask)\n",
        "        self.t = torch.nn.ModuleList([t_func(input_dim, hidden_dims, output_dim) for _ in range(len(masks))])\n",
        "        self.s = torch.nn.ModuleList([s_func(input_dim, hidden_dims, output_dim) for _ in range(len(masks))])\n",
        "        \n",
        "    def g(self, z, w):\n",
        "        x = z\n",
        "        for i in range(len(self.t)):\n",
        "            x_ = x*self.mask[i]\n",
        "            x_wf = torch.cat([x_, w],dim=1)\n",
        "            s = self.s[i](x_wf)*(1 - self.mask[i])\n",
        "            t = self.t[i](x_wf)*(1 - self.mask[i])\n",
        "            x = x_ + (1 - self.mask[i]) * (x * torch.exp(s) + t)\n",
        "        return x\n",
        "\n",
        "    def f(self, x, w):\n",
        "        log_det_J, z = x.new_zeros(x.shape[0]), x\n",
        "        for i in reversed(range(len(self.t))):\n",
        "            z_ = self.mask[i] * z\n",
        "            z_wf = torch.cat([z_, w],dim=1)\n",
        "            s = self.s[i](z_wf) * (1-self.mask[i])\n",
        "            t = self.t[i](z_wf) * (1-self.mask[i])\n",
        "            z = (1 - self.mask[i]) * (z - t) * torch.exp(-s) + z_\n",
        "            log_det_J -= s.sum(dim=1)\n",
        "        return z, log_det_J\n",
        "\n",
        "    \n",
        "    def log_prob(self, x, w):\n",
        "        z, logp = self.f(x, w)\n",
        "        return self.prior.log_prob(z) + logp\n",
        "        \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "id": "-hmeXujkXqe8",
      "metadata": {
        "id": "-hmeXujkXqe8"
      },
      "outputs": [],
      "source": [
        "flow_wf = RealNVP_wf(s_func, t_func, masks, prior)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "id": "APUFt1qN_1eN",
      "metadata": {
        "id": "APUFt1qN_1eN"
      },
      "outputs": [],
      "source": [
        "# Training and test loops\n",
        "\n",
        "def train_loop_flow(dataloader, model, optimizer):\n",
        " \n",
        "    size = len(dataloader.dataset)\n",
        "    train_loss = 0\n",
        "\n",
        "    for batch, (X, y) in enumerate(dataloader):\n",
        "        # Compute negative log probability loss\n",
        "\n",
        "        loss = - model.log_prob(y, X)\n",
        "    \n",
        "        train_loss += loss.detach().sum()\n",
        "        loss = loss.mean()\n",
        "\n",
        "        # Backpropagation\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if batch % 50 == 0:\n",
        "            loss, current = loss.item(), batch * len(X)\n",
        "            print(f\"Loss: {loss:>7f}  [{current:>5d}/{size:>5d} samples]\")\n",
        "            \n",
        "    average_loss = train_loss.item() / size\n",
        "    print('Average loss: {:.4f}'.format(average_loss))\n",
        "    return average_loss\n",
        "            \n",
        "              \n",
        "def test_loop_flow(dataloader, model):\n",
        "    size = len(dataloader.dataset)\n",
        "    test_loss = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for X, y in dataloader:\n",
        "\n",
        "            loss = - model.log_prob(y, X)\n",
        "            test_loss += loss.sum()\n",
        "\n",
        "    test_loss /= size\n",
        "    print(f\"Test loss: {test_loss:>8f} \\n\")\n",
        "    return test_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "id": "77MzeB_vFTUc",
      "metadata": {
        "id": "77MzeB_vFTUc"
      },
      "outputs": [],
      "source": [
        "optimizer = torch.optim.Adam([p for p in flow_wf.parameters() if p.requires_grad==True], lr=1e-3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "-wcmRTRX_0BA",
      "metadata": {
        "id": "-wcmRTRX_0BA"
      },
      "outputs": [],
      "source": [
        "epochs = 5\n",
        "train_history = []\n",
        "test_history = []\n",
        "for t in range(epochs):\n",
        "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
        "    loss = train_loop_flow(train_dataloader, flow_wf, optimizer)\n",
        "    train_history.append(loss)\n",
        "    loss = test_loop_flow(test_dataloader, flow_wf)\n",
        "    test_history.append(loss)\n",
        "print(\"Done!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "43bd8a0e-f291-49d8-b646-d40541997aac",
      "metadata": {
        "id": "43bd8a0e-f291-49d8-b646-d40541997aac"
      },
      "outputs": [],
      "source": [
        "epochs = np.arange(1, len(train_history) + 1)\n",
        "plt.plot(epochs, train_history, label = 'train loss')\n",
        "plt.plot(epochs, test_history, label = 'test loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "99e0dc79-3256-4a0c-81c1-a71f9854faa0",
      "metadata": {
        "id": "99e0dc79-3256-4a0c-81c1-a71f9854faa0"
      },
      "outputs": [],
      "source": [
        "num_posteriors = 3\n",
        "num_samples = 10000\n",
        "\n",
        "for n in range(num_posteriors):\n",
        "    test_x, test_y = test_dataset[n]\n",
        "\n",
        "    # Repeat same wf for a number of samples\n",
        "    wf = torch.from_numpy(np.tile(test_x, (num_samples, 1))).type(torch.FloatTensor)\n",
        "\n",
        "    # Sample from base distribution\n",
        "    z = prior.sample((num_samples,1)).view(num_samples,-1)\n",
        "\n",
        "    # Predict a posterior\n",
        "    pred_samples = cp.asarray(flow_wf.g(z, wf).detach())\n",
        "\n",
        "    # Undo the standardization\n",
        "    pred_samples = parameters_std * pred_samples + parameters_mean\n",
        "    truth = parameters_std * cp.asarray(test_y) + parameters_mean\n",
        "\n",
        "    # Plot\n",
        "    corner.corner(get_wrapper(pred_samples), truths=get_wrapper(truth), labels=['$f0$', '$amp$'])\n",
        "    plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "_Q91cUVTExWk",
        "7ee627d9-db98-4d9f-82f6-99e51264de02",
        "do2CRoAHExWo",
        "akCnF7aXExWp"
      ],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}